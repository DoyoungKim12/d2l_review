# 4.6. Generalization in Classification
<br>

지금까지 우리는 다중 출력과 소프트맥스 함수를 적용한 선형 신경망을 훈련시켜 다중 분류 문제를 해결하는 방법에 초점을 맞추었다. 
모델의 출력을 확률값으로 해석하여 교차 엔트로피 손실 함수를 도출했는데, 이는 (고정된 파라미터 집합에 대해) 모델이 각 라벨에 할당하는 음의 log likelihood를 계산한다. 
그리고 마지막으로, 우리의 모델을 학습용 데이터셋에 적합(fitting)시켜 이러한 도구들을 실전에 적용한다. 
그러나 항상 그렇듯이, 우리의 목표는 학습에 사용되지 않은(unseen) 데이터를 통해 경험적으로 평가되는 **일반적인 패턴**을 배우는 것이다. 
학습용 데이터셋에 대한 높은 정확도는 아무 의미가 없다.
각각의 입력이 고유하더라도(그리고 실제로 대부분의 고차원 데이터셋에서는 각 입력이 고유함(unique)), 
첫 번째 에폭에서 학습에 사용된 데이터셋 전체를 암기하고, 이후 입력를 볼 때마다 레이블을 조회하는 것만으로도 학습용 데이터셋에 대해서는 완벽한 정확도를 달성할 수 있다. 
그리고, 학습용 데이터셋의 정확한 라벨을 암기하는 것은 당연히 새로운 입력에 대해 분류하는 방법을 알려주지 않는다. 
그 이상의 지침이 없으면, 새로운 입력을 만날 때마다 무작위 추측에 의존해야 할 수 있다.
<br>

아래의 질문들은 지금 당장 관심을 가져야 할 것들이다: 
1. 모집단에 대한 분류기의 정확도를 정확하게 추정하기 위해 얼마나 많은 테스트 셋이 필요한가? 
2. 동일한 테스트로 모델을 반복 평가하면 어떻게 되는가? 
3. 우리의 선형 모델을 학습용 데이터셋에 적합시킨 것이 우리의 나이브한 기억 체계보다 더 잘 동작할 것이라고 기대하는 이유는 무엇인가?
<br>

Section 3.6에서는 선형 회귀의 관점에서 과적합과 일반화의 기본을 소개했지만, 이 장에서는 통계적 학습 이론의 몇 가지 기본 아이디어를 소개하면서 조금 더 깊이 있게 다룰 것이다. 
학자들은 많은 경우에 **일반화를 선험적으로 보장**할 수 있는 것을 밝혀냈다. 
많은 모델, 추구하는 일반화 갭 $\epsilon$ (training error와 test error의 차이)의 상한에 대해 우리는 일반적으로 필요한 샘플 수 $n$ 을 결정할 수 있다. 
따라서 우리의 훈련용 데이터셋에 최소한 n개의 샘플이 포함되어 있다면, 우리의 경험적 오류는 모든 데이터 생성 분포에 대해 실제 오류 $\epsilon$ 내에 있을 것이다.
하지만 아쉽게도 이러한 종류의 보장은 깊은 지적 구성 요소를 제공하지만, 딥러닝 실무자 입장에서는 그 실용적 유용성이 제한적이라는 것이 밝혀졌다. 
간단히 말해서, 이러한 보장은 신경망의 일반화를 보장하기 위해 
우리가 그 신경망에 대해 일반적으로 훨씬 적은 수의 샘플(수천 개 정도)로 상당히 잘 일반화하는 것을 발견한 경우에도 
선험적으로 터무니없는 수의 샘플(아마도 수조 개 이상)이 필요하다는 것을 시사한다. 
따라서 딥러닝 실무자는 선험적 보장이라는 것을 완전히 포기하는 경우가 많은데, 
대신 과거에 유사한 문제에 대해 해당 모델이 잘 일반화했던 사실을 근거로 특정 메소드를 차용하고 경험적 평가를 통해 사후 일반화를 보증한다. 
Section 5에서는 일반화의 개념을 다시 검토하고, 신경망이 현실적인 문제에서의 일반화가 가능한 이유를 설명하려고 시도한 방대한 과학 문헌에 대해 가볍게 소개할 것이다.
<br>

## 4.6.1 The Test Set

일반화 오차를 평가하기 위한 가장 전형적인 방법으로 이미 테스트 셋에 의존하기 시작했으므로, 그러한 오차 추정치의 특성에 대해 논의하는 것으로 시작해보자. 
그 파라미터 등을 어떻게 도출했는지에 대한 것은 일단 배제한 채로, 고정된 분류기 $f$ 에 초점을 맞추자. 그리고 분류기 $f$ 를 훈련시키는 데 사용되지 않은 새로운 샘플 데이터 셋 
$\mathcal{D} = {(\mathbf{x}^{(i)},y^{(i)})}_{i=1}^n$ 를 가지고 있다고 가정하자. 
$\mathcal{D}$ 에 대한 분류기 $f$ 의 **경험적 오차(empirical error)** 는 단순히 예측값 $f(\mathbf{x}^{(i)})$ 이 실제 레이블과 일치하지 않는 인스턴스의 비율로, 아래의 식으로 주어진다:
<br>

$$\epsilon_\mathcal{D}(f) = \frac{1}{n}\sum_{i=1}^n \mathbf{1}(f(\mathbf{x}^{(i)}) \neq y^{(i)}).$$
<br>

반면, **모집단 오차(population error)** 는 모집단(확률밀도함수 $p(x,y)$ 중 하나인 어떤 분포 $P(X,Y)$ )에서 기대할 수 있는, 우리의 분류기와 실제 라벨 값이 다른 샘플의 비율이다.
<br>

$$\epsilon(f) =  E_{(\mathbf{x}, y) \sim P} \mathbf{1}(f(\mathbf{x}) \neq y) = \int\int \mathbf{1}(f(\mathbf{x}) \neq y) p(\mathbf{x}, y) \;d\mathbf{x} dy.$$
<br>

$\epsilon(f)$ 이 우리가 실제로 찾고자 하는 것이지만, 
한 사람 한 사람을 일일히 직접 측정하지 않고는 많은 인구 집단에서 평균 키를 직접 관찰할 수 없는 것처럼 우리는 그것을 직접 관찰할 수는 없다. 
우리는 오직 샘플에 근거하여 이 값을 추정할 수 있다. 
테스트셋 $\mathcal{D}$ 는 모집단을 '통계적으로' 대표하기 때문에, 우리는 경험적 오차를 모집단 오차의 통계적 추정치로 볼 수 있다. 
게다가 우리가 관심있는 모집단 오차는 (랜덤 변수 $\mathbf{1}(f(\mathbf{x}) \neq y)$ 의) 기대치이고, 경험적 오차는 표본 평균이기 때문에 
모집단 오차를 추정하는 것은 단순히 고전적인 평균 추정의 문제가 된다. (Section 2.6에서 언급함)
<br>

중심극한정리(central limit theorem)라고 불리는 확률 이론의 중요한 고전적 정리는 
평균 $\mu$ 과 표준 편차 $\sigma$ 를 가지는 임의의 분포로부터 추출된 n개의 랜덤 샘플이 있을 때, 
표본의 수가 무한대에 가까워짐에 따라 표본 평균은 모평균이 그 중심에 있고 표준편차가 $\sigma/\sqrt{n}$ 인 정규 분포에 가까워지는 경향이 있다는 것을 보장한다. 
이것은 우리에게 중요한 것을 말해준다: 
샘플의 수가 증가함에 따라, 우리의 테스트 오차(= 경험적 오차, $\epsilon_\mathcal{D}(f)$ 는 $\mathcal{O}(1/\sqrt{n})$ 의 비율로 모집단 오차 $\epsilon(f)$ 에 수렴해야 한다.
따라서, 테스트 오차를 두 배 더 정확하게 추정하기 위해서는, 우리는 4배 더 큰 테스트 셋을 수집해야 한다. 
시험 오차를 100배 더 줄이려면, 테스트 셋을 기존에 비해 1만 배나 더 수집해야 하는 것이다. 
일반적으로, 이러한 비율 $\mathcal{O}(1/\sqrt{n})$ 은 우리가 통계적으로 기대할 수 있는 최선의 것이다.
<br>

테스트 오차가 실제 모집단 오차에 수렴하는 기울기(asymptotic rate)에 대해 이처럼 어느 정도는 알게 되었기에, 우리는 이제 몇가지 중요한 디테일에 집중할 수 있다.
확률변수 $$\mathbf{1}(f(\mathbf{x}) \neq y)$은 오직 0과 1 중 하나의 값만을 가질 수 있고, 따라서 이는 베르누이 확률변수(1의 값을 가질 확률을 나타내는 파라미터(모수)로 특정되는 확률분포)라는 사실을 다시 상기해보자.
여기서 1이라는 값은 우리가 만든 분류기가 에러를 발생시켰다는 것을 의미하고, 따라서 확률변수의 파라미터는 모집단 오차율 $\epsilon(f)$ 이 된다.
베르누이 분포의 분산은 파라미더에 의해 결정되고, 그 파라미터는 여기서는 $\epsilon(f)$ 이다.( $\epsilon(f)(1-\epsilon(f))$ )
$\epsilon(f)$ 이 우리가 알 수 없는 값이기는 하지만, 1보다 클 수는 없다는 것을 안다. 
또한 분산은 모집단 오차가 0.5에 가까울 때 가장 크다는 점, 그리고 0 또는 1에 가까울 때 가장 작아진다는 점을 알 수 있는데,
이는 오차 $\epsilon(f)$ 의 추정치인 $\epsilon_\mathcal{D}(f)$ 의 'asymptotic 표준편차'가 $\sqrt{0.25/n}$ 보다 커질 수는 없다는 것을 보여준다.
(0.25는 0.5(1 - 0.5)를 계산한 값으로, 분산의 최대치)
<br>

이 '비율'은 우리가 한정된 수의 샘플을 가지고 있을 때보다는 테스트 셋이 무한대에 근접해가는 상황을 특정하고 있다는 점을 무시한다면,
이는 우리가 만약 테스트 오차를 모집단 오차에 근접하도록 해서 하나의 표준편차가가 $\pm 0.01$ 의 구간 내에 존재하길 바란다면, 
우리는 대략 2500개의 샘플을 수집해야 한다는 것을 말해준다.
만약 우리가 2개의 표준편차가 구간 안에 존재하도록 해서 $\epsilon_\mathcal{D}(f) \in \epsilon(f) \pm 0.01$ 될 확률이 95%가 되도록 적합시키고 싶다면,
우리는 1만개의 샘플이 필요할 것이다!
<br>

이는 ML의 많은 유명한 벤치마크들에서의 테스트셋 크기로 드러난다.
여러분은 0.01, 또는 그 이하의 오차율 개선으로 인해 매년 수천 개의 응용 딥러닝 논문이 출판된다는 것을 알게 되면 놀랄지도 모르겠다.
물론, 오차율이 0에 더욱 가까워질때, 0.01만큼의 개선은 중요한 문제가 될 수 있다.
<br>

지금까지의 분석에서 성가신 부분 중 하나는 샘플 크기가 무한대로 점점 커질 때 $\epsilon_\mathcal{D}$ 와 $\epsilon$ 사이의 관계가 어떻게 발전되는지, 
즉 점근적인(asymptotics) 부분에서만 무언가를 알게 해준다는 점이다.
다행스럽게도, 우리가 다루는 확률변수는 그 범위가 정해져있고(bounded), 우리는 Hoeffding 부등식을 적용하여 유효한 유한 표본 구간를 얻을 수 있다.
<br>

$$P(\epsilon_\mathcal{D}(f) - \epsilon(f) \geq t) < \exp\left( - 2n t^2 \right).$$
<br>

추정치 $\epsilon_\mathcal{D}$ 와 실제 오차율 $\epsilon$ 의 차이가 0.01을 초과하지 않는다는 보증을 95%의 신뢰구간 내에서 허용할 수 있는 
가장 작은 데이터셋의 크기를 구한다면, 위의 점근 분석(asymptotic analysis)에 의해 제안된 10000개와 비교하여 약 15000개의 샘플이 필요하다는 것을 알 수 있다.
통계학을 더 자세히 공부해본다면 이러한 결론을 인정하는 트렌드가 일반적으로 유지되었다는 것을 알 수 있다. 
유한한 샘플을 가정할 때에도 유지되는 보장은 일반적으로 약간 더 보수적이다. 
사물의 체계에서, 이 숫자들은 그렇게 멀리 떨어져 있지 않으며, 우리가 법정에 설 수 있다는 보장은 없더라도 대략적인 수치를 제공하는 점근 분석의 일반적인 유용성을 반영한다.
<br>



